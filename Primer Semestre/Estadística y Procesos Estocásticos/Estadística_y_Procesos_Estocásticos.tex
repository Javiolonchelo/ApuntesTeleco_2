\documentclass[a4paper]{book}

\input{../../Archivos comunes/Preamble.tex} % Se incluye el preámbulo

\renewcommand{\vec}[1]{\mathbf{#1}} % Redefinición de vectores para adecuarse a la notación de negrita usada en esta asignatura.

\title{\Huge Estadística y Procesos Estocásticos\\
\Large Apuntes de clase}
\author{Javier Rodrigo López \thanks{E-mail: \href{mailto:javiolonchelo@gmail.com}{\texttt{javiolonchelo@gmail.com}}}}
\date{\today}

%%% INICIO DEL DOCUMENTO %%%
\begin{document}

\setlength{\wpYoffset}{-5 cm}
\ThisCenterWallPaper{0.65}{./Imágenes/Boticelli.jpg}
\maketitle

% Marca de agua
\AddToShipoutPictureFG{
	\begin{tikzpicture}[overlay,remember picture]
		\path (current page.south west) -- (current page.north east)
		node[midway,scale=8,color=lightgray,sloped,opacity=0.05] {Javier Rodrigo López};
	\end{tikzpicture}
}

% Logotipos UPM y ETSIST
\begin{figure}[t!]
	\centering
	\begin{subfigure}[b]{0.65\linewidth}
		\includegraphics[width=\linewidth]{../../Archivos comunes/upm_logo.png}
	\end{subfigure}
	\begin{subfigure}[b]{0.25\linewidth}
		\includegraphics[width=\linewidth]{../../Archivos comunes/etsist_logo.png}
	\end{subfigure}
\end{figure}


\newpage
\setlength{\parskip}{0.5em}
\phantomsection

\addcontentsline{toc}{section}{Introducción}
\section*{Introducción}
Esta pequeña recopilación de fórmulas, teoremas y demás apuntes de teoría ha sido elaborada durante el primer semestre del curso 2019-2020, en la escuela \href{https://www.etsist.upm.es/}{\textbf{ETSIST}} de la \href{http://www.upm.es/}{\textbf{UPM}} por Javier Rodrigo López, alumno de 1º de Ingeniería de Sonido e Imagen.
bruuh
\newpage

\setlength{\parskip}{0em}
\tableofcontents
\setlength{\parskip}{0.5em}

\chapter*{Conceptos básicos de teoría de conjuntos}
\section*{Notación básica}
\begin{definicion}
	Un \textbf{conjunto} es una colección de elementos considerada como una sola entidad. Los conjuntos se denotan con letras mayúsculas, $A,B,C \ldots \ $ , mientras que los elementos se denotan con letras minúsculas, $a,b,c \ldots $

	Utilizamos la notación $x\in A$ para indicar que $x$ es un elemento de $A$. Si, por el contrario, $x$ no pertenece a $A$, entonces se escribe como $x\not \in A$.

	Si todos los elementos de un conjunto $A$ pertenecen a su vez a un conjunto $B$, entonces se dice que $A$ es subconjunto de $B$ y se denota como $A\subset B$.

	Si $A$ y $B$ tienen exactamente los mismos elementos, entonces $A=B$.
\end{definicion}

\section*{Operaciones con conjuntos}
\begin{definicion}
	La \textbf{unión} de $A$ y $B$ se denota como $A\cup B$ y contiene a todos los elementos de $A$ y todos los elementos de $B$.
\end{definicion}

\begin{definicion}
	La \textbf{intersección} de $A$ y $B$ se denota como $A\cap B$ y contiene solo a los elementos que se encuentran en $A$ y en $B$ al mismo tiempo. Si no comparten elementos, se dice que son \textbf{disjuntos}. La intersección de estos es el conjunto vacío, denotado como $\emptyset$. De esta forma, $A\cap B = \emptyset$
\end{definicion}

\begin{definicion}
	El \textbf{complementario} de un conjunto $A$ contiene todos los elementos que no se encuentran en $A$. Se denota como $\overline{A}$ y se cumple que: \[A \cup \overline{A} = \Omega \qquad A \cap \overline{A} = \emptyset\]
\end{definicion}

\begin{definicion}
	La \textbf{diferencia} de dos conjuntos $A, B$ se define como el conjunto de los elementos de $A$ que no pertenecen a $B$. Se denota como $A-B$, aunque también se puede escribir como $A\cap \overline{B}$.
\end{definicion}

\subsection*{Propiedades}
Estas operaciones verifican las propiedades conmutativas, asociativas y distributivas, además de las siguientes propiedades:
\[A \cup A = A \cap A = A\]
\[A\cup \Omega = \Omega \]
\[A \cap \Omega = A\]

También podemos incluir las \textbf{Leyes de De Morgan}: \[\overline{A\cup B} = \overline{A} \cap \overline{B}\]
\[\overline{A\cap B} = \overline{A} \cup \overline{B}\]
Estas leyes son muy importantes y tienen una propiedad interesante. No hace falta que sean una pareja de conjuntos, también puede suceder algo como lo siguiente: \[\overline{A\cap B \cap C} = \overline{A} \cup \overline{B} \cup \overline{C}\]

\chapter{Probabilidad}


\section{Espacio probabilístico}
\begin{definicion}
	Un experimento es \textbf{aleatorio} si se verifica que: \begin{itemize}
		\item Todos los resultados se conocen de antemano.
		\item Cualquier realización da lugar a un resultado que no se conoce previamente.
		\item Puede repetirse en condiciones idéntica.
	\end{itemize}
\end{definicion}

\begin{definicion}
	El \textbf{espacio muestral} $ \Omega $ asociado a un experimento es el conjunto de todos los posibles resultados del experimento.

	Un suceso $A$ es un subconjunto del espacio muestral $\Omega$. Los sucesos que constan de un único elemento se denominan \textbf{sucesos elementales}. El espacio de sucesos $S$ es el conjunto de los subconjuntos de $\Omega$.
\end{definicion}

\begin{definicion}
	La \textbf{frecuencia relativa} de un suceso $A$ se define como \[f_r(A) = \frac{n_A}{n} \qquad \qquad \left\lbrace \begin{matrix*}[l] n & \equiv & \text{número de veces que se realiza el experimento}\\
			n_A & \equiv & \text{número de veces que sucede A}
		\end{matrix*} \right. \]

	La \textbf{ley de regularidad estadística} dice que la frecuencia relativa tiende a un número fijo según se incremente el valor de $n$.
\end{definicion}

\subsubsection*{Propiedades de la frecuencia relativa}
\begin{itemize}
	\item $0\leq f_r(A)\leq 1$
	\item $f_r(\Omega )=1$
	\item $ f_r\left( A \cup B \right) = f_r(A) + f_r(B)\qquad \quad $ solo si $A$ y $B$ son incompatibles $\left( A \cap B = \emptyset \right)$
\end{itemize}
\newpage

\begin{definicion}
	Una \textbf{probabilidad} $P$ sobre $(\Omega, S)$ es una función $P: S \longrightarrow [0,1]$ que verifica:
\end{definicion}

\begin{itemize}
	\item $P(\Omega )=1$
	\item Para toda colección de sucesos $A_1,A_2,\ldots , A_n$ incompatibles dos a dos\\ $\left( A_i \cap A_j = \emptyset \ \ \forall i \not = j \right)$, se verifica que: \[P\left( \bigcup _{i=1}^n A_i \right) = \sum^{n}_{i=1}{P\left( A_i \right)} \]
\end{itemize}

\subsubsection*{Consecuencias de esta definición}
\vspace{\parskip}
\begin{itemize}
	\item $P\left( \overline{A} \right) = 1 - P(A)$
	\item $P(\emptyset )=0$
	\item Si $A\subset B \Longrightarrow P(A) \leq P(B)$
	\item $P(A-B) = P(A\cap \overline{B})= P(A) - P(A\cap B)$
	\item $ P(A\cup B) = P(A) + P(B) - P(A\cap B)$
\end{itemize}

\begin{nota}
	Esta última puede interpretarse de forma diferente para tres sucesos: \[P(A\cup B \cup C) = P(A) + P(B) + P(C) - P(A\cap B) - P(B\cap C) - P(A\cap C) + P(A\cap B\cap C)\]
\end{nota}

En general, para un número $n$ de sucesos: \[\begin{split}
		P\left( A_1\cup \ldots \cup A_n \right) = \sum^{n}_{i=1}{P\left( A_i \right)}-\sum_{i<j}{P\left( A_i \cap A_j \right)} +
		\sum_{i<j<k}{P\left( A_i \cap A_j \cap A_k \right)}+ \ldots + \\
		+ \left( -1 \right)^{n+1}P\left( A_1 \cap \ldots \cap A_n \right)
	\end{split}
\]

\begin{definicion}
	La terna $(\Omega, S, P)$ se llama \textbf{espacio probabilístico}.
\end{definicion}

\subsection*{Probabilidad en espacios muestrales finitos}
Si $\Omega$ es finito, cada conjunto con un elemento $\left\lbrace \omega _j \right\rbrace , j =1,2,\ldots ,n$ , es un suceso elemental y es suficiente asignar probabilidades a cada $\left\lbrace \omega _j \right\rbrace$. Si $A \in S$, se tiene: \[P(A) =\sum_{\omega _j \in A}{P(\{ \omega _j\} )}\]

Si particularizamos podemos obtener la \textbf{Regla de Laplace}\footnote{Para poder utilizar la Regla de Laplace, necesitamos que los sucesos sean equiprobables.}.

Si $P(\{ \omega _j\} ) = \frac{1}{n}, j=1,2,\ldots ,n$; tenemos que:
\[\boxed{P(A) = \frac{\text{Nº de elementos de }A}{\text{Nº de elementos de }\Omega}}\]

\section{Combinatoria}

Tenemos que tener en cuenta lo que significan los \textbf{elementos} y el \textbf{orden} en el que se encuentran dentro del conjunto.

Si no importa el orden, estamos hablando de \textbf{combinaciones}:
\begin{itemize}
	\item Combinaciones de $m$ elementos tomados de $n$ en $n (n\leq m)$: \[C_{m,n}\cdot P_n = V_{m,n} \qquad \Rightarrow C_{m,n} = {\binom{m}{n}} = \frac{m!}{\left( m-n \right)! \, n!}\]
\end{itemize}

Ahora bien, si el orden importa tendremos que distinguir otras dos situaciones. Si cogemos todos los elementos del conjunto, hablaremos de \textbf{permutaciones}.
\begin{itemize}
	\item Permutaciones de $m$ elementos: \[P_m = m!\]
	\item Permutaciones con repetición de $m$ elementos. Es decir, que hay un elemento que se repite $r_1$ veces, otro que se repite $r_2$ y demás: \[\sum^{i}_{j=1}{r_j}=m \qquad \qquad P^{r_1,r_2,\, \ldots\,  , r_i}_m=\frac{m!}{r_1!\, r_2!\, \ldots \, r_i!}\]
\end{itemize}

Si, por el contrario, los juntamos en grupos más pequeños, estaremos hablando de \textbf{variaciones}.

\begin{itemize}
	\item Variaciones con repetición de $m$ elementos tomados de $n$ en $n$: \[VR_{m,n}=m^n\]
	\item Variaciones sin repetición de $m$ elementos tomados de $n$ en $n (n\leq m)$: \[V_{m,n}=\frac{m!}{\left( m-n \right)!} \]
\end{itemize}

\section{Probabilidad condicionada. Independencia.}
\begin{definicion}
	Sea $A$ un suceso de probabilidad $P(A)>0$, y $B$ otro suceso de probabilidad $P(B)$. La probabilidad de $B$ puede dejar de ser la misma, si se sabe que ha ocurrido el suceso $A$.

	Sean $A$ y $B$ dos sucesos tal que $P(A)>0$. Llamaremos \textbf{probabilidad condicionada} del suceso $B$ respecto al suceso $A$, y la denotaremos por $\probCond{B}{A}$, al cociente: \[ \probCond{B}{A}  = \frac{P\left(  B\cap A\right)}{P(A)}\]

	La fórmula de la probabilidad condicionada también se puede expresar como: \[\probCond{B}{A} = P(A)\ \probCond{B}{A} \]

	Que se podría generalizar a tres sucesos $A, B$ y $C$, resultando en la \textbf{regla de la multiplicación}: \[P(A\cap B \cap C)=P(A)\probCond{B}{A}\probCond{C}{A\cap B}\]

	olololo
\end{definicion}

\begin{definicion}
	Si $\probCond{B}{A} =P(B)$ siendo $P(A)>0$, entonces que haya ocurrido $A$ no influye en la probabilidad que tenía $B$ de ocurrir, y se dice que $A$ y $B$ son independientes.

	Despejando: \[P(A\cap B) = P(A)\, P(B)\]
\end{definicion}

\begin{definicion}
	Diremos que los sucesos $A_1,A_2,\, \ldots\, ,A_n$ son mutuamente independientes si la probabilidad conjunta de todos los subconjuntos que pueden formarse con ellos es el producto de las probabilidades individuales. Es decir: \[P\left( \bigcap_{i\in I} A_i \right) = \prod_{i\in I}{P(A_i)} \qquad \forall I \left[ 1, 2, \, \ldots	\, ,n \right] \]
\end{definicion}

\begin{teorema}
	El \textbf{teorema de la probabilidad total} nos dice que, sean los sucesos\\ $C_1, \psus ,C_n$ incompatibles dos a dos de modo que $\bigcup^{n}_{i=1}=\Omega$, entonces:
	\[\boxed{P(A)=\sum^{n}_{i=1}{\probCond{A}{C_1}}P(C_i)}\qquad  \forall A \in \mathcal{S}\]
\end{teorema}

\begin{teorema}
	El teoriema de Bayes nos dice, en las mismas hipótesis que el teorema anterior, que: \[\boxed{\probCond{C_i}{A}=\frac{\probCond{A}{C_1}P(C_i)}{\sum^{n}_{i=1}{\probCond{A}{C_i}P(C_i)}}}\]
\end{teorema}

Ejemplo 6 del documento anexo (falta referencia). %Aquí falta la referencia.

$P(B) = 3$



\chapter{Variables aleatorias}

\section{Variable aleatoria discreta}
Se dice que una variable aleatoria es \textbf{discreta} si solo puede tomar un número finito de valores, o bien un número infinito numerable (como pueden ser los números naturales $\mathbb{N}$.

\subsection{Función de probabilidad}
Si la v.a.\footnote{v.a. $\equiv$ variable aleatoria} $X$ puede tomar unos ciertos valores $x_n$ con $n=1, 2, \psus $

La \textbf{función de probabilidad} es una función que asigna a cada valor $x_n$ una probabilidad.

\subsection{Media}
La \textbf{media} o \textbf{esperanza matemática} de una v.a. $X$ nos proporciona información sobre la localización de $X$. Se representa como $\mu _X$\footnote{Es común representar la media como $\mu$ a secas.} o como $E[X]$.
\[\mu _X = E[X] = \sum^{\infty}_{n=1}{x_n \cdot P(X=x_n)}\]

\begin{nota}
	Es importante mencionar que la esperanza es un operador lineal.
\end{nota}

\subsection{Varianza y desviación típica}
La \textbf{varianza} de una v.a. $X$ nos proporciona información sobre la dispersión de $X$. Se representa como $\Var(X)$.
\[\Var(X) = \sigma_X^2 = E\left[ \left( X-\mu \right)^2 \right]\]

A veces es más útil representar la \textbf{desviación típica}. Se denota por la letra $\sigma$.
\[\sigma _X = \sqrt{\Var(X)}\]

\subsection{Función de distribución}

Sea $F$ la \textbf{función de distribución} (también conocida como función de distribución acumulativa) de la v.a. $X$. Las propiedades que caracterizan a la función de distribución son:

\begin{enumerate}
	\item Es monótona decreciente, es decir: $\displaystyle{\qquad \forall x , y\in \mathbb{R}, x<y \ \Rightarrow F(x) \leq F(y)}$
	\item $\displaystyle{\lim_{x \to -\infty} F(x)=0}$
	\item $\displaystyle{\lim_{x \to \infty} F(x)=1}$
	\item $F$ es continua por la derecha en $ \mathbb{R} $. Es decir: $\displaystyle{\quad \lim_{x \to a^+} F(x)=F(a), \quad \forall a \in \mathbb{R}}$
\end{enumerate}

%Sean un número $h \in \mathbb{N}$ y una v.a. discreta $X$, con función de probabilidad $f$ y esperanza matemática $E[X]$. Llamaremos \textbf{momento de orden h} de $X$ a la expresión:
%\[\alpha _h = E\left[ X^h \right] = \left\{ \begin{matrix*}[l]
%\displaystyle{\sum^{k}_{i=1}{x_i^h \cdot  f(x_i)} \qquad \Im (X) = \left\lbrace \rep{x}{1}{k} \right\rbrace }\\[15pt]
%\displaystyle{\sum^{\infty}_{i=1}{x_i^h \cdot  f(x_i)} \qquad \Im (X) = \left\lbrace \repinf{x}{1}{2} \right\rbrace }
%\end{matrix*} \right.\]
%
%Llamaremos \textbf{momento central de orden h} a la expresión:
%
%\[\mu _h = E\left[\left( X - E[X] \right)^h \right] = \left\{ \begin{matrix*}[l]
%\displaystyle{\sum^{k}_{i=1}{\left( x_i - E[X] \right)^h \cdot  f(x_i)} \qquad \Im (X) = \left\lbrace \rep{x}{1}{k} \right\rbrace }\\[15pt]
%\displaystyle{\sum^{\infty}_{i=1}{\left( x_i - E[X] \right)^h \cdot  f(x_i)} \qquad \Im (X) = \left\lbrace \repinf{x}{1}{2} \right\rbrace }
%\end{matrix*} \right.\]



\subsection{Distribuciones}

\subsubsection{Distribución uniforme discreta}
Una v.a. $X$ tiene una distribución uniforme discreta si es una v.a. discreta en la que sus valores son todos \textbf{equiprobables}.

\subsubsection{Pruebas de Bernoulli}
Una prueba de Bernoulli es un experimento aleatorio con dos posibles resultados: \textbf{éxito} $(E)$ y \textbf{fracaso} $(\overline{E})$. Si se realizan varias pruebas de Bernoulli, los resultados serán independientes entre sí.

La probabilidad del éxito se denota como $p$, de modo que la probabilidad del fracaso será $(1-p)$.

\subsubsection{Distribución binomial}
Generalizando un poco, si $N$ es el número de pruebas de Bernoulli que realizamos, la probabilidad de obtener $n$ éxitos será: \[\boxed{P\left( X=n \right)={\binom{N}{m}} p^n\left( 1-p \right)^{N-n}} \qquad n= 0,1,\psus , N\]

Si una v.a. $X$ tiene una distribución binomial, se denota como: \[X \sim \B \left( N,p \right)\]

\begin{itemize}
	\item \textbf{Media:} $\mu = Np$
	\item \textbf{Varianza:} $\sigma ^2 = Np(1-p)$
\end{itemize}

\subsubsection{Distribución geométrica}
En esta distribución también se parte de las pruebas de Bernoulli. Sin embargo, y a diferencia de la distribución binomial, nos interesará conocer el \textbf{número de pruebas hasta el primer éxito}. Una v.a. $T$ tiene distribución geométrica si:

\[\boxed{P\left( T=n \right)= \left( 1-p \right)^{n-1}n} \qquad n= 0,1,2,\psus\]

Si una v.a. $T$ tiene una distribución geométrica, se denota como: \[T \sim \Geo(p)\]

\begin{itemize}
	\item \textbf{Media:} $\displaystyle{\mu = \frac{1}{p}}$
	\item \textbf{Varianza:} $\displaystyle{\sigma ^2 = \frac{1-p}{p^2}}$
\end{itemize}

\begin{nota}
	Si lo reescribimos para la probabilidad de fracaso $q$ (recordamos que $q = 1-p$), entonces: \[P\left( T>n \right) = q^n\]
\end{nota}

\subsubsection{Distribución binomial negativa}
Este tipo de distribución nos interesa conocer el número de pruebas hasta obtener el $r$-ésimo éxito.

Se dice que una v.a. $X$ tiene una distribución binomial negativa de parámetros $r$ y $p$, si: \[\boxed{P\left( X=n \right)={\binom{n-1}{r-1}} p^r\left( 1-p \right)^{n-r}} \qquad n= r,(r+1),(r+2),\psus \]

Si una v.a. $X$ tiene una distribución binomial negativa, se denota como: \[X \sim \BN \left( r,p \right)\]

\begin{itemize}
	\item \textbf{Media:} $\displaystyle{\mu = \frac{r}{p}}$
	\item \textbf{Varianza:} $\displaystyle{\sigma ^2 = \frac{r(1-p)}{p^2}}$
\end{itemize}

\subsubsection{Distribución de Poisson}
Una v.a. $X$ tiene distribución de Poisson si representa \textbf{el número de ciertos eventos que ocurren en un periodo fijo de tiempo} (siempre que los eventos se produzcan de forma aleatoria en el tiempo). Se cumple que: \[\boxed{P\left( X=n \right)=e^{-\lambda} \frac{\lambda ^n}{n!}} \qquad n= 0,1,2,\psus \]

Si una v.a. $X$ tiene una distribución de Poisson, se denota como: \[X \sim \Poisson \left( \lambda \right)\]

\begin{itemize}
	\item \textbf{Media:} $\displaystyle{\mu = \lambda}$
	\item \textbf{Varianza:} $\displaystyle{\sigma ^2 = \lambda}$
\end{itemize}

\begin{nota}

	Si $N$ es muy grande, una v.a. que tenga distribución binomial \textbf{puede aproximarse como una distribución de Poisson}, cometiendo un error prácticamente despreciable.

	La forma realizar esta aproximación es igualando las medias típicas de cada distribución: \[Np = \lambda\]
\end{nota}

\section{Variable aleatoria continua}
Una v.a. $X$ es continua si existe una función $f_X(x)$ llamada \textbf{función de densidad} tal que: \[\boxed{P\left( a<X\leq b \right) = \int_a^b{f(x)dx}} \qquad  f(x) \geq 0\: ,\qquad
	\left\{ \begin{matrix*}[l]
		a,b\in \mathbb{R}\\
		a\leq b
	\end{matrix*}\right. \]

\begin{nota}
	Como $P\left( -\infty < X < \infty \right) = 1$, la función de densidad verfica: \[\int_{-\infty}^{\infty}{f(x)dx} = 1\]
\end{nota}

\subsection{Media y varianza}
La \textbf{media} $(\mu)$ de una v.a. $X$ se define de forma análoga a cómo se definía en variables aleatorias discretas: \[\mu = \int_{-\infty}^{\infty}{x f(x) dx}\]

La varianza se define exactamente de la misma forma: \[\Var(X) = \sigma ^2\]

\subsection{Función de distribución}
La función de distribución con v.a. continua también se puede definir de forma análoga a como hicimos con v.a. discreta: \[\boxed{F(x) = P\left( X\leq x \right) = \int_{-\infty}^x{f(\xi )d\xi}}\]

Esta es una función acotada entre 0 y 1 y, además, es monótona creciente.

La función de distribución nos permite calcular \textbf{probabilidades de intervalos} de la siguiente forma: \[\left\{ \begin{matrix*}[l]
		P(a<X<b) = F(b) - F(a)\\[5pt]
		P(X>a) = 1 - F(a) \end{matrix*}\right.\]

Un resultado intereseante haberlo definido así lo encontramos cuando intentamos calcular la probabilidad en un punto. \[P(X=a) = 0 \qquad \forall a \in \mathbb{R}\]

\begin{nota}
	En variable continua, podemos relacionar la función de distribución con la función de densidad.
	\[F'(x) = f(x)\]
\end{nota}


\subsection{Distribuciones}
\subsubsection{Distribución uniforme}
Una v.a. $X$ tiene distribución uniforme en el intervalo $(a,b)$ si su función de densidad es: \[f(x) = \left\{ \begin{matrix*}[l]
		\displaystyle{\frac{1}{b-a}} & \quad a<x<b\\[15pt]
		0 & \quad \text{en el resto de casos}
	\end{matrix*}\right.\]

\begin{figure}[h!]
	\begin{subfigure}[b]{\linewidth}
		\centering
		\includegraphics[width=0.4\linewidth]{./Imágenes/aaa.png}
	\end{subfigure}
	\caption{Representación de la función de densidad de una v.a. de distribución uniforme.}
\end{figure}

A veces, es común verla como $f(x) = \frac{1}{b-a}$ para $a<x<b$. Se da por supuesto que, fuera de ese rango, la función es nula.

Para indicar que $X$ tiene una distribución uniforme, lo escribimos como: \[X\sim \U(a,b)\]

\textbf{¿Cuándo la voy a usar?} En algunas situaciones, y en la mayoría de los ejercicios que tendremos que resolver, es muy útil saber que: \[P\left( X \in (c,d) \right)= \frac{d-c}{b-a} \qquad \quad \text{siempre y cuando }(c,d)\subset (a,b)\]

\begin{itemize}
	\item \textbf{Media:} $\displaystyle{\mu = \frac{a+b}{2}}$
	\item \textbf{Varianza:} $\displaystyle{\sigma ^2 = \frac{\left( b-a \right)^2}{12}}$
\end{itemize}

\subsubsection{Distribución exponencial}
En las v.a. con distribución exponencial, nos interesa el \textbf{tiempo que hay que esperar hasta que suceda cierto evento }. Una v.a. $T$ tiene distribución exponencial si su función de densidad es: \[f(t) = \left\{ \begin{matrix}
		\lambda e^{-\lambda t} & \quad t>0           \\[5pt]
		0                      & \quad  \text{resto}
	\end{matrix} \right.\qquad\qquad  \left( \lambda >0 \right)\]

Para indicar que $T$ tiene una distribución exponencial, lo escribimos como: \[T\sim \Exp(\lambda )\]

\begin{itemize}
	\item \textbf{Media:} $\displaystyle{\mu = \frac{1}{\lambda}}\quad $ (tiempo medio de espera)
	\item \textbf{Varianza:} $\displaystyle{\sigma ^2 = \frac{1}{\lambda ^2}}$
\end{itemize}

\subsubsection{Distribución normal}
Una v.a. $X$ tiene distribución normal si su función de densidad es la \textbf{campana de Gauss}: \[f(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{1}{2}\left( \frac{x-\mu }{\sigma} \right)^2} \qquad -\infty <x< \infty \]

Sin embargo, no es posible calcular su función de distribución en términos generales.

Para indicar que $X$ tiene una distribución normal, caracterizada por su media y su desviación típica, lo escribimos como: \[X \sim \N(\mu , \sigma ) \]

Además, se suele utilizar la \textbf{distribución normal estándar} $\N(0,1)$, ya que está tabulada. En otras palabras, para realizar los ejercicios utilizaremos una tabla con los valores más utilizados. Sin embargo, en la tabla no aparecen valores negativos de $X$. Eso se debe a que se puede calcular como $\Phi (-x) = 1 - \Phi(x)$.

Cuando nos encontremos con una v.a. $X$ que se distribuya con una normal, lo que debemos hacer es \textbf{tipificarla}. Esto signfica que definiremos otra v.a. $Z$ que modelice a $X$ para que tenga distribución normal.
\[\boxed{X \sim \N(\mu ,\sigma ) \ \longrightarrow \ Z = \frac{X-\mu}{\sigma} \sim \N(0,1)}\]

\section{Desigualdad de Chebyshev}
Sea $X$ una v.a. con media $\mu$ y varianza $\sigma ^2$, entonces para todo $k>0$ se cumple lo siguiente: \[P\left( \abs{X-\mu} < k\sigma \right)\geq 1 - \frac{1}{k^2}\]

\begin{nota}
	Es más fácil comprender la desigualdad de Chebyshev si la reescribimos de esta forma: \[ P\left[ (\mu - k\sigma )< X < (\mu +k\sigma ) \right] \geq 1 - \frac{1}{k^2}\]
\end{nota}


\section{Cuantil}
\subsection*{En v.a. discreta}
Sea $X$ una v.a. discreta, llamaremos \textbf{cuantil de orden} $p$, denotado como $q_p$, al menor valor en el que se cumpla que: \[F_X(x)\geq p \qquad \qquad \left( 0 < p < 1 \right) \]

\subsection*{En v.a. continua}
Sea $T$ una v.a. continua, llamaremos llamaremos \textbf{cuantil de orden} $p$, denotado como $q_p$, al número que verifica: \[P\left( T \leq q_p \right) = \int_{-\infty}^{q_p}{f(x)dx} = p\]

O, en otras palabras: \[\boxed{F_T(q_p)=p}\]


\section{Percentil}
El percentil es un tipo de cuantil que separa las muestras en 100 grupos diferentes. Para calcular el \textbf{percentil de orden} $n$ de una v.a., basta con saber que: \[P_n = q_{\frac{n}{100}}\]


\chapter{Vectores aleatorios}
\section{Variable aleatoria bidimensional}

Una variable aleatoria bidimensional se puede definir como una transformación tal que:
\[\left( X,Y \right) : \Omega \longrightarrow \mathbb{R}^2\]

De modo que, teniendo el experimento $\omega \in \Omega$, la variable aleatoria bidimensional asigna a cada resultado de dicho experimento un elemento de $\mathbb{R}^2$ que es $\left( X(\omega ),Y(\omega )\right)$.

Esta es \textbf{la misma definición} que para variables aleatorias unidimensionales, pero extrapolada a dos dimensiones. Se podría decir que una variable aleatoria bidimensional está compuesta de dos variables aleatorias unidimensionales, como en un paquete.

\section{Variable aleatoria bidimensional discreta}

La \textbf{función de probabilidad conjunta} de una variable aleatoria bidimensional discreta es una función que proporciona la información esencial de las variables $X$ e $Y$, y se define como:
\[P\left( X=x_i,Y=y_j \right) = P\left( X=x_i \cap Y=y_j \right) \, , \qquad i, j = 1, 2, \dots \] 

A partir de esta función, se pueden calcular las funciones de probabilidad de las variables aleatorias $X$ e $Y$. En este contexto, se les denomina \textbf{funciones de probabilidad marginales}:
\[ P\left( X=x_i \right) = \sum_{j=1}^{\infty} P\left( X=x_i, Y=y_j \right) \, , \qquad i = 1, 2, \dots \]
\[ P\left( Y=x_j \right) = \sum_{i=1}^{\infty} P\left( X=x_i, Y=y_j \right) \, , \qquad j = 1, 2, \dots \]

Es importante observar que la probabilidad del espacio muestral es 1, por lo que se verifica que:
\[ \sum_{i=1}^{\infty}\sum_{j=1}^{\infty} P\left( X=x_i, Y=y_j \right) = 1 \]

\section{Variable aleatoria bidimensional continua}

La \textbf{función de probabilidad conjunta} de una variable aleatoria bidimensional continua es una función que proporciona la información esencial de las variables $X$ e $Y$, y se define como:

\[ P\left( \left( X,Y \right) \in D\right) = \iint_{D}f_{X,Y}(x,y)\dd{y} \dd{x}\]

O, en particular:
\[P\left( a\leq X \leq b, c\leq Y \leq d\right) = \int_{a}^{b}\int_{c}^{d} f_{X,Y}(x,y)\dd{y} \dd{x}\]

Además:
\[\boxed{F_{X,Y}(x,y) = P \left( X\leq x, Y\leq y\right)} = \int_{-\infty}^{x}\int_{-\infty}^{y} f_{X,Y}(\xi , \eta ) \dd{\xi} \dd{\eta}\]

Al igual que antes, la propabilidad del espacio muestral es 1. Por tanto, se verifica que:
\[\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f_{X,Y}(x,y) \dd{x} \dd{y} = 1\]

Como consecuencia del teorema fundamental del cálculo, se obtiene la siguiente expresión:
\[\pdv[2]{}{x}{y} F_{X,Y}(x,y) = f_{X,Y}(x,y)\]

Las variables aleatorias continuas $X$ e $Y$ tienen funciones de densidad, que en este caso denominaremos \textbf{funciones de densidad marginales}

\section{Independencia de variables aleatorias}
Sea $\left( X,Y\right)$ una variable aleatoria bidimensional, se dice que $X$ e $Y$ son independientes si para cualquiera $A$ y $B$:
\[P\left( X\in A, Y\in B\right) = P\left(X\in A\right)\cdot P\left(Y\in B\right)\]

Si $X$ e $Y$ son independientes, las variables aleatorias definidas a continuación también serán independientes:
\[U=g(X) \qquad \qquad V=h(X)\]

\section{Momentos}

\subsection{Esperanza}

Sea $\left(X,Y\right)$ una variable aleatoria discreta, la \textbf{esperanza} de la variable aleatoria $g\left(X,Y\right)$ es:
\[E\left[g\left(X,Y\right)\right] = \sum_{x_i,y_j\in S}g\left(x_i,y_j\right)P\left(X=x_i, Y=y_j\right)\]

Sea $\left(X,Y\right)$ una variable aleatoria continua, y análoga a la definición anterior, la esperanza de la variable aleatoria $g\left(X,Y\right)$ es:
\[E\left[g\left(X,Y\right)\right] = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}g\left(x,y\right)f_{X,Y}(x,y)\dd{x} \dd{y}\]

La esperanza es un operador \textbf{lineal}.

\subsection{Covarianza}

La covarianza se usa para \textbf{medir el grado de correlación} entre las variables $X$ e $Y$. Se define como:
\[\Cov \left( X,Y \right) = E \left[\left(X-E\left[X\right]\right) \cdot \left(Y - E\left[Y\right]\right)\right]\]

Sin embargo, \textbf{la forma habitual} de calcular la covarianza es la siguiente:
\[\Cov \left( X,Y \right) = E\left[X\cdot Y\right] - E\left[X\right]E\left[Y\right]\]

Para dos números $a,b \in \mathbb{R}$, se cumple que:
\[\Cov \left( aX,bY \right) = ab\Cov \left( X,Y \right)\]

Esta propiedad puede dificultar algunas operaciones. Por eso, se define el \textbf{coeficiente de correlación lineal} mediante la normalización de la covarianza:
\[\rho \left(X,Y\right) = \frac{\Cov \left( X,Y \right)}{\sigma _X \sigma _Y} \]

Es importante recalcar que $\rho \left( aX,bY \right) = \rho \left( X,Y \right) $. Además, se verifica que:
\[-1\leq \rho \left( X,Y \right) \leq 1 \]

Las variables aleatorias $X$ e $Y$ son \textbf{incorreladas} si $\rho \left( X,Y \right)=0$.

Si las variables aleatorias $X$ e $Y$ son independientes, son incorreladas. Por lo tanto:
\[X \text{ e } Y \text{ son independientes} \ \Longrightarrow \left\lbrace \begin{matrix*}[l]
	E \left[ X \cdot Y \right] = E \left[ X \right] E \left[ Y \right] \\[5pt] 
	\Cov \left( X,Y \right) = 0 \\[5pt] 
	\rho \left( X,Y \right) = 0
\end{matrix*} \right. \] 

\subsection{Notación matricial}
El \textbf{vector de medias} se define como:
\[ \vec{m} = \left[ 
\begin{matrix}
	E \left[ X \right]\\ 
	E \left[ Y \right]
\end{matrix} \right] \]

La \textbf{matriz de covarianza} se define como:
\[M=\left[ 
\begin{matrix}
	\Var \left( X \right)& \Cov \left( X,Y \right)\\ 
	\Cov \left( X,Y \right)& \Var \left( Y \right)
\end{matrix} \right]\]

\section{Variable aleatoria multidimensional}

Prácticamente todas las definiciones mostradas para dos variables aleatorias se pueden generalizar para $n$ variables aleatorias.

Una variable aleatoria $n$-dimensional se define como una aplicación:
\[\left( X_1,X_2,\dots , X_n \right):\Omega \longrightarrow \mathbb{R}^n\]
Esta variable aleatoria asigna a cada resultado del excperimento $\omega \in \Omega$ un elemento\\ $\left( X_1(\omega ), X_2(\omega ) \dots X_n (\omega )\right)\in \mathbb{R}^n$

Para cualquiera de las operaciones lineales, resulta apropiada la notación por columnas:
\[\vec{X} = \left[ 
\begin{matrix}
	X_1\\ 
	X_2\\ 
	\vdots \\ 
	X_n
\end{matrix} \right]\]

Por lo tanto, escribiremos el vector de medias como:
\[\vec{m}_{\vec{X}} = E \left[ \vec{X} \right]= \left[ 
\begin{matrix}
	E \left[ X_1 \right]\\ 
	E \left[ X_2 \right]\\ 
	\vdots \\ 
	E \left[ X_n \right]
\end{matrix} \right] \]

Y la matriz de covarianzas como:
\[ M_{\vec{X}} = \left[ 
\begin{matrix}
	\Var \left( X_1 \right) & \Cov \left( X_1, X_2 \right) & \cdots & \Cov \left( X_1, X_n \right)\\ 
	\Cov \left( X_1, X_2 \right) & \Var \left( X_2 \right) & \cdots & \Cov \left( X_2, X_n \right)\\ 
	\vdots & \vdots & \ddots & \vdots \\
	\Cov \left( X_1,X_n \right) & \Cov \left( X_2, X_n \right) & \cdots & \Var \left( X_n \right)
\end{matrix} \right]\]

\subsubsection{Linealidad}
Si se realiza una combinación lineal con las variables aleatorias $\left( X_1,X_2, \dots , X_n \right)$ se obtiene una variable aleatoria:
\[ Y = a_1X_1 + a_2X_2 + \dots + a_nX_n \]

Podemos expresar la variables aleatoria $Y$ de la siguiente forma:
\[ Y = A \vec{X}, \qquad A = \left[ 
\begin{matrix}
	a_1 & a_2 & \cdots & a_n
\end{matrix} \right] \]

Por la linealidad de la \textbf{esperanza}, tenemos que:
\[ E \left[ Y \right] = a_1E \left[ X_1 \right] + a_2 E \left[ X_2 \right] + \dots + a_n E \left[ X_n \right] \]

La \textbf{varianza} de $Y$ será:
\[ \Var \left( Y \right) = A \times M_{\vec{X}} \times A ^{\top} \]

Donde $A ^{\top} $ es la matriz traspuesta de $A$. Se puede generalizar este resultado para $m$ combinaciones lineales. Suponiendo que:
\[ \vec{Y} = A \vec{X} + \vec{v} \]
 
Donde $A$ es una matriz de dimensión $m \times n$ y $\vec{b}$ es un vector columna, entonces la variables aleatoria $m$-dimensional $\vec{Y}$ tiene un vector de medias $\vec{m}_{\vec{Y}}$ y una matriz de covarianza $M_{\vec{Y}}$ tales que:
\[ \vec{m}_{\vec{Y}} = A \vec{m}_{\vec{X}} + \vec{b} \, ; \qquad \qquad \vec{m}_{\vec{Y}} = A \vec{m}_{\vec{X}} A ^{\top} \]

\section{Distribución multinomial}

Si se realizan $n$ pruebas de Bernoulli, la variable aleatoria bidimensional $\left( X_1, X_2 \right)$ definida por:
\[ \begin{matrix*}[l]
	X_1 \equiv \text{número de éxitos}\\[5pt] 
	X_2 \equiv \text{número de fracasos}
\end{matrix*} \]

Esta variable solo podrá tomar los valores $\left( n_1, n_2 \right)$ con $n_1 = 0,1, \dots , n$ y $n_2 = n - n_1$. Para estos valores:
\[ P \left( X_1 = n_1, X_2 = n_2 \right) = \frac{n!}{n_1!n_2!} p_1^{n_1} p_2^{n_2}\]

Donde $p_1 = p$ es la probabilidad de éxito y $p_2 = 1-p$ es la probabilidad de fracaso.

Un caso intereseante es aquel en el que en cada una de las $n$ pruebas se puedan obtener $k$ posibles resultados $A_1,A_2, \dots ,A_k$ con probabilidades $p_1,p_2, \dots ,p_k$, donde necesariamente $p_1 +p_2 + \dots + p_k = 1$. La variable $n$-dimensional $\left( X_1, \dots X_k \right)$ definida por:
\[ \begin{matrix*}[l]
	X_1 \equiv \text{número de veces que se obtiene }A_1\\[5pt] 
	X_2 \equiv \text{número de veces que se obtiene }A_2\\[5pt] 
	\ \, \vdots \\[5pt] 
	X_k \equiv \text{número de veces que se obtiene }A_k
\end{matrix*} \]

solo puede tomar valores $\left( n_1, n_2, \dots , n_k \right)$ con $n_1,\dots ,n_k=0,1,\dots ,n$ y $n_1 + \dots + n_k = 1$. Para estos valores se tiene que:
\[ P \left( X_1=n_1, \dots , X_k = n_k \right) = \frac{n!}{n_1!n_2!\dots n_k!} p_1^{n_1} \dots p_k^{n_k} \]

Se dice que es $\left( X_1,\dots ,X_k \right)$ sigue una distribución multinomial de parámetros $n,p_1,p_2,\dots p_k$, y se denota como:
\[ \left( X_1,\dots ,X_k \right) \sim \Mult \left( n,p_1,p_2,\dots p_k \right) \]

\section{Distribución normal n-dimensional}

Un vector aleatorio $ X = \left( X_1, \dots , X_n \right) $ sigue una distribución normal si la denominada función de densidad
\[ f_{X_1,\dots , X_n}\left( x_1, \dots , x_n \right) = \frac{\partial ^n}{\partial x_1 \dots \partial x_n}F_{X_1, \dots , X_n} \left( x_1, \dots , x_n \right)\]
es igual a
\[ \frac{1}{\abs{M_{\vec{X}}}^{\frac{1}{2} } \left( 2 \pi  \right) ^{\frac{n}{2}}} e^{-\frac{1}{2}\left( \vec{X} - \vec{m}_{\vec{X}} \right) ^{\top} M_{\vec{X}}^{-1} \left( \vec{X} - \vec{m}_{\vec{X}} \right) }\]

donde $M_{\vec{X}}$ es la matriz de covarianzas y $\vec{m}_{\vec{X}}$ es el vector de medias.

\section{Teorema central del límite}

Vamos a utilizar la definición de este teorema que nos será útil para resolver los ejercicios. La definición completa es [FALTA REFERENCIA].

Sean $X_1,\dots , X_n$ variables aleatorias independientes e idénticamente distribuidas, cada una con media $\mu$ y varianza $\sigma ^2$.

El \textbf{teorema central del límite} afirma que si $n$ es grande la suma $S_n$ tiene aproximadamente distribución normal de media $n\mu$ y desviación típica $\sigma \sqrt{n}$ (varianza $n\sigma ^2$), siendo esta suma:
\[ S_n = X_1 + X_2 + \dots + X_n \]

Equivalentemente, la \textbf{variable normalizada} $\frac{S_n-n\mu}{\sigma \sqrt{n}}$ tiene aproximadamente distribución normal de media 0 y varianza 1.

\section{Chi cuadrado y la t de Student}

Sean $Z_1,\dots ,Z_n$ variables aleatorias independientes con distribución normal estándar, $Z_i \sim N \left( 0,1 \right)$, con $i=1,\dots ,n$.

La distribución de probabilidad que sigue la variable aleatoria
\[ X=Z_1^2+\dots +Z_n^2 \]
se denomina chi-cuadrado con $n$ grados de libertad. Se denota $X\sim \chi _n^2$. La distribución $\chi _n^2$ es positiva. Su media y su varianza son:
\[ E (X) = n \, ; \qquad \qquad \Var \left( X \right)=2n \]

Sea $X\sim \chi _n^2$, y $Z$ una variable aleatoria con distribución normal estándar, $Z\sim N(0,1)$, independiente de $X$. La distribución de probabilidad que sigue la variable aleatoria
\[Y=\frac{Z}{\sqrt{X/n}}\]
se denomina $t$ de Student con $n$ grados de libertad. Se denota $Y\sim t_n$. La $t$ de Student tiene una función de densidad simétrica muy similar, casi igual si $n$ es grande, a la de una normal $N(0,1)$. La principal diferencia es la varianza, que vale:
\[ \Var \left( Y \right)=\frac{n}{n-2}  \]

\chapter{Inferencia estadística}

\section{Estadística descriptiva de una variable: momentos, cuantiles, box-plot, histograma, función de distribución empírica y cálculo de proporciones}
\section{Muestra aleatoria. Media muestral y varianza muestral. Estimación paramétrica}

\section{Intervalos de confianza para la media y para proporciones poblacionales}

\section{Contraste de hipótesis. Nivel de significación y p-valor}



\chapter{Procesos estocásticos}

\section{Definición de proceso estocástico}
Un proceso estocástico es una familia de variables aleatorias definidas sobre un espacio probabilístico.

Es decir, para cada $ t\in T, X(t)$ es una variable aleatoria; el índice $t$ representa a menudo el tiempo y así diremos, que un proceso estocástico es una familia de variables aleatorias que describe la evolución a lo largo del tiempo de algún proceso físico.

Otro punto de vista:

Sea $E$ un experimento aleatorio cuyo espacio probabilístico asociado $(\Omega , S, P)$. Un \textbf{proceso estocástico} o proceso aleatorio es un conjunto de funciones temporales $x(t,\omega )$, cada una correspondiente a un punto particular $\omega$ del espacio muestral $\Omega$. Así, asociado a cada resultado específico $\omega$, tenemos una función específica $x(t,\omega )$, a la que llamaremos una realización del proceso.

Denotaremos el proceso mediante: $X_t\equiv X(t) \equiv X(t,\omega )$, donde $t$ es el tiempo y $\omega$ una variable que representa un resultado en el espacio muestral $\Omega$.

Normalmente, un proceso estocástico será denotado como $x(t)$.

\section{Procesos estocásticos en tiempo continuo}
\textbf{Primer ejemplo.}

Tiramos un dado. Si se obtiene 1, 2 ó 3, entonces:
\[X(t) = t\]
Si se obtiene 4 ó 5, entonces:
\[X(t) = 2t\]
Si se obtiene un 6, entonces:
\[X(t) = 3t\]

Esto se puede modelizar de la siguiente manera:
\[X(t) = A\cdot t\]
De modo que la probabilidad de $A$ será:
\begin{center}
	\begin{tabular}{r || c | c | c}
		$A$    & 1              & 2              & 3              \\ \hline
		$P(A)$ & $\sfrac{1}{2}$ & $\sfrac{1}{3}$ & $\sfrac{1}{6}$
	\end{tabular}
\end{center}

\textbf{Segundo ejemplo.}

La señal $X(t) = \cos\left( t+\phi \right)$, donde la fase $\phi$ es desconocida, se puede considerar como un proceso estocástico, donde $\phi$ es una variable aleatoria con distribución uniforme en el intervalo $[0, 2\pi )$




\section{Procesos estocásticos en tiempo discreto}

Simplemente son procesos estocásticos pero en tiempo discreto.

Por ejemplo, las pruebas de Bernoulli y el proceso binomial.



\section{Distribuciones de primer y segundo orden, media, autocorrelación y autocovarianza}

\section{Proceso de Bernoulli. Caminos aleatorios. Procesos normales. Proceso de Poisson}

\section{Procesos estacionarios. Densidad espectral}

\section{Sistemas lineales y procesos estocásticos}

\chapter{Prácticas con software estadístico}


\section{Modelos de distribución de probabilidad más comunes}

\section{Estadística descriptiva}

\section{Muestreo. Estimación puntual}

\section{Estimación por intervalos de confianza}

\section{Contraste paramétrico}

%%% FIN DE LOS APUNTES %%%

%%% BIBLIOGRAFÍA %%%
% Por defecto, se encuentra desactivada. Esto disminuye el tiempo de procesado. Se puede activar cuando se vaya a exportar el PDF definitivo

%\newpage
%\phantomsection
%\label{sec:bibliografia_final}
%\renewcommand{\refname}{Bibliografía}
%\addcontentsline{toc}{section}{Bibliografía}
%\bibliography{bibliografia} % Nombre del archivo (sin ".bib")
%\bibliographystyle{bababbrv} 

\end{document}
